{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning\n",
    "\n",
    "In this file, instructions how to approach the challenge can be found."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to work on different types of Machine Learning problems:\n",
    "\n",
    "- **Regression Problem**: The goal is to predict delay of flights.\n",
    "- **(Stretch) Multiclass Classification**: If the plane was delayed, we will predict what type of delay it is (will be).\n",
    "- **(Stretch) Binary Classification**: The goal is to predict if the flight will be cancelled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.model_selection as ms\n",
    "import harness\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split():\n",
    "    flights = pd.read_csv('data/flights_1%.csv')\n",
    "    flights_train, flights_test = ms.train_test_split(\n",
    "        flights, test_size=0.2, random_state=729\n",
    "    )\n",
    "    flights_train.to_csv('data/flights_train.csv', index_label='id')\n",
    "    flights_test.to_csv('data/flights_test.csv', index_label='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_test_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_train = pd.read_csv('data/flights_train.csv', index_col=0)\n",
    "flights_test = pd.read_csv('data/flights_test.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_0 = pd.read_csv('weather_0.csv', index_col=0)\n",
    "weather_1 = pd.read_csv('weather_1.csv', index_col=0)\n",
    "weather_2 = pd.read_csv('weather_2.csv', index_col=0)\n",
    "weather_3 = pd.read_csv('weather_3.csv', index_col=0)\n",
    "weather_4 = pd.read_csv('weather_4.csv', index_col=0)\n",
    "weather = pd.concat([weather_0,weather_1,weather_2,weather_3,weather_4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Task: Regression Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The target variable is **ARR_DELAY**. We need to be careful which columns to use and which don't. For example, DEP_DELAY is going to be the perfect predictor, but we can't use it because in real-life scenario, we want to predict the delay before the flight takes of --> We can use average delay from earlier days but not the one from the actual flight we predict.  \n",
    "\n",
    "For example, variables **CARRIER_DELAY, WEATHER_DELAY, NAS_DELAY, SECURITY_DELAY, LATE_AIRCRAFT_DELAY** shouldn't be used directly as predictors as well. However, we can create various transformations from earlier values.\n",
    "\n",
    "We will be evaluating your models by predicting the ARR_DELAY for all flights **1 week in advance**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature engineering will play a crucial role in this problems. We have only very little attributes so we need to create some features that will have some predictive power.\n",
    "\n",
    "- weather: we can use some weather API to look for the weather in time of the scheduled departure and scheduled arrival.\n",
    "- statistics (avg, mean, median, std, min, max...): we can take a look at previous delays and compute descriptive statistics\n",
    "- airports encoding: we need to think about what to do with the airports and other categorical variables\n",
    "- time of the day: the delay probably depends on the airport traffic which varies during the day.\n",
    "- airport traffic\n",
    "- unsupervised learning as feature engineering?\n",
    "- **what are the additional options?**: Think about what we could do more to improve the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_clean = harness.clean_train(flights_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_clean_copy = flights_clean.copy()\n",
    "flights_clean_copy['month']=flights_clean_copy.fl_date\n",
    "flights_clean_copy.month = flights_clean_copy.month.map(lambda v: int(v[5:7]))\n",
    "flights_clean_copy['day']=flights_clean_copy.fl_date\n",
    "flights_clean_copy.day = flights_clean_copy.day.map(lambda v: int(v[8:]))\n",
    "flights_clean_copy['haul']=flights_clean_copy.crs_elapsed_time/60\n",
    "flights_clean_copy['haul'] = pd.cut(flights_clean_copy.haul,bins=[0,3,6,12],labels=['Short','Medium','Long'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_with_weather = flights_clean_copy.merge(\n",
    "    weather, left_on=['fl_date', 'origin_city_name'], right_on=['date', 'city']\n",
    ").merge(\n",
    "    weather, left_on=['fl_date', 'dest_city_name'], right_on=['date', 'city'],\n",
    "    suffixes=('_origin', '_dest')\n",
    ")\n",
    "\n",
    "weather_category_map = {\n",
    "    'Partially cloudy': 'Cloudy',\n",
    "    'Clear': 'Sunny',\n",
    "    'Rain, Partially cloudy': 'Rainy',\n",
    "    'Rain, Overcast': 'Rainy',\n",
    "    'Overcast': 'Cloudy',\n",
    "    'Rain': 'Rainy',\n",
    "    'Snow, Partially cloudy': 'Snowy',\n",
    "    'Snow, Overcast': 'Snowy',\n",
    "    'Snow': 'Snowy',\n",
    "}\n",
    "flights_with_weather['weather_origin'] = flights_with_weather.conditions_origin.map(weather_category_map)\n",
    "flights_with_weather['weather_dest'] = flights_with_weather.conditions_dest.map(weather_category_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_with_weather = flights_clean_copy.merge(flights_with_weather, how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_with_weather['conditions_origin'] = flights_with_weather['conditions_origin'].fillna('Unknown')\n",
    "flights_with_weather['conditions_dest'] = flights_with_weather['conditions_dest'].fillna('Unknown')\n",
    "flights_with_weather['weather_origin'] = flights_with_weather['weather_origin'].fillna('Unknown')\n",
    "flights_with_weather['weather_dest'] = flights_with_weather['weather_dest'].fillna('Unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_with_weather = harness.add_grouped_stats(flights_with_weather,'conditions_origin')\n",
    "flights_with_weather = harness.add_grouped_stats(flights_with_weather,'conditions_dest')\n",
    "flights_with_weather = harness.add_grouped_stats(flights_with_weather,'weather_origin')\n",
    "flights_with_weather = harness.add_grouped_stats(flights_with_weather,'weather_dest')\n",
    "flights_with_weather = harness.add_grouped_stats(flights_with_weather,'op_unique_carrier')\n",
    "flights_with_weather = harness.add_grouped_stats(flights_with_weather,'fl_date')\n",
    "flights_with_weather = harness.add_grouped_stats(flights_with_weather,'dest_city_name')\n",
    "flights_with_weather = harness.add_grouped_stats(flights_with_weather,'origin_airport_id')\n",
    "flights_with_weather = harness.add_grouped_stats(flights_with_weather,'origin_city_name')\n",
    "flights_with_weather = harness.add_grouped_stats(flights_with_weather,'dest_airport_id')\n",
    "flights_with_weather = harness.add_grouped_stats(flights_with_weather,'day')\n",
    "flights_with_weather = harness.add_grouped_stats(flights_with_weather,'month')\n",
    "flights_with_weather = harness.add_grouped_stats(flights_with_weather,'haul')\n",
    "flights_with_weather = harness.add_grouped_stats(flights_with_weather,'tail_num')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_with_weather = flights_with_weather.drop(['conditions_origin',\n",
    "                                                  'conditions_dest',\n",
    "                                                  'weather_origin', 'date_dest',\n",
    "                                                  'weather_dest', 'dup',\n",
    "                                                  'op_unique_carrier', 'date_origin',\n",
    "                                                  'fl_date','dest_city_name',\n",
    "                                                  'origin_airport_id','origin_city_name',\n",
    "                                                  'dest_airport_id','day','month','haul',\n",
    "                                                  'branded_code_share',\n",
    "                                                  'mkt_carrier','origin','dest',\n",
    "                                                  'tail_num','mkt_unique_carrier'], axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_with_weather['tail_num_delay_std'] = flights_with_weather['tail_num_delay_std'].fillna(0)\n",
    "flights_with_weather['dest_airport_id_delay_std'] = flights_with_weather['dest_airport_id_delay_std'].fillna(0)\n",
    "flights_with_weather['origin_city_name_delay_std'] = flights_with_weather['origin_city_name_delay_std'].fillna(0)\n",
    "flights_with_weather['origin_airport_id_delay_std'] = flights_with_weather['origin_airport_id_delay_std'].fillna(0)\n",
    "flights_with_weather['dest_city_name_delay_std'] = flights_with_weather['dest_city_name_delay_std'].fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection / Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to apply different selection techniques to find out which one will be the best for our problems.\n",
    "\n",
    "- Original Features vs. PCA conponents?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA()\n",
    "pca.fit(flights_with_weather)\n",
    "exp_var_cumul = np.cumsum(pca.explained_variance_ratio_)\n",
    "\n",
    "px.area(\n",
    "    x=range(1, exp_var_cumul.shape[0] + 1),\n",
    "    y=exp_var_cumul,\n",
    "    labels={\"x\": \"# Components\", \"y\": \"Explained Variance\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=n_components)\n",
    "components = pca.fit_transform(flights_with_weather)\n",
    "\n",
    "total_var = pca.explained_variance_ratio_.sum() * 100\n",
    "\n",
    "labels = {str(i): f\"PC {i+1}\" for i in range(n_components)}\n",
    "labels['color'] = 'Median Price'\n",
    "\n",
    "fig = px.scatter_matrix(\n",
    "    components,\n",
    "    dimensions=range(n_components),\n",
    "    labels=labels,\n",
    "    title=f'Total Explained Variance: {total_var:.2f}%',\n",
    ")\n",
    "fig.update_traces(diagonal_visible=False)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.pipeline import make_pipeline\n",
    "print(__doc__)\n",
    "\n",
    "# Code source: Tyler Lanigan <tylerlanigan@gmail.com>\n",
    "#              Sebastian Raschka <mail@sebastianraschka.com>\n",
    "\n",
    "# License: BSD 3 clause\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "FIG_SIZE = (10, 7)\n",
    "\n",
    "\n",
    "features, target = load_wine(return_X_y=True)\n",
    "\n",
    "# Make a train/test split using 30% test size\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target,\n",
    "                                                    test_size=0.30,\n",
    "                                                    random_state=RANDOM_STATE)\n",
    "\n",
    "# Fit to data and predict using pipelined GNB and PCA.\n",
    "unscaled_clf = make_pipeline(PCA(n_components=2), GaussianNB())\n",
    "unscaled_clf.fit(X_train, y_train)\n",
    "pred_test = unscaled_clf.predict(X_test)\n",
    "\n",
    "# Fit to data and predict using pipelined scaling, GNB and PCA.\n",
    "std_clf = make_pipeline(StandardScaler(), PCA(n_components=2), GaussianNB())\n",
    "std_clf.fit(X_train, y_train)\n",
    "pred_test_std = std_clf.predict(X_test)\n",
    "\n",
    "# Show prediction accuracies in scaled and unscaled data.\n",
    "print('\\nPrediction accuracy for the normal test dataset with PCA')\n",
    "print('{:.2%}\\n'.format(metrics.accuracy_score(y_test, pred_test)))\n",
    "\n",
    "print('\\nPrediction accuracy for the standardized test dataset with PCA')\n",
    "print('{:.2%}\\n'.format(metrics.accuracy_score(y_test, pred_test_std)))\n",
    "\n",
    "# Extract PCA from pipeline\n",
    "pca = unscaled_clf.named_steps['pca']\n",
    "pca_std = std_clf.named_steps['pca']\n",
    "\n",
    "# Show first principal components\n",
    "print('\\nPC 1 without scaling:\\n', pca.components_[0])\n",
    "print('\\nPC 1 with scaling:\\n', pca_std.components_[0])\n",
    "\n",
    "# Use PCA without and with scale on X_train data for visualization.\n",
    "X_train_transformed = pca.transform(X_train)\n",
    "scaler = std_clf.named_steps['standardscaler']\n",
    "X_train_std_transformed = pca_std.transform(scaler.transform(X_train))\n",
    "\n",
    "# visualize standardized vs. untouched dataset with PCA performed\n",
    "fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=FIG_SIZE)\n",
    "\n",
    "\n",
    "for l, c, m in zip(range(0, 3), ('blue', 'red', 'green'), ('^', 's', 'o')):\n",
    "    ax1.scatter(X_train_transformed[y_train == l, 0],\n",
    "                X_train_transformed[y_train == l, 1],\n",
    "                color=c,\n",
    "                label='class %s' % l,\n",
    "                alpha=0.5,\n",
    "                marker=m\n",
    "                )\n",
    "\n",
    "for l, c, m in zip(range(0, 3), ('blue', 'red', 'green'), ('^', 's', 'o')):\n",
    "    ax2.scatter(X_train_std_transformed[y_train == l, 0],\n",
    "                X_train_std_transformed[y_train == l, 1],\n",
    "                color=c,\n",
    "                label='class %s' % l,\n",
    "                alpha=0.5,\n",
    "                marker=m\n",
    "                )\n",
    "\n",
    "ax1.set_title('Training dataset after PCA')\n",
    "ax2.set_title('Standardized training dataset after PCA')\n",
    "\n",
    "for ax in (ax1, ax2):\n",
    "    ax.set_xlabel('1st principal component')\n",
    "    ax.set_ylabel('2nd principal component')\n",
    "    ax.legend(loc='upper right')\n",
    "    ax.grid()\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use different ML techniques to predict each problem.\n",
    "\n",
    "- linear / logistic / multinomial logistic regression\n",
    "- Naive Bayes\n",
    "- Random Forest\n",
    "- SVM\n",
    "- XGBoost\n",
    "- The ensemble of your own choice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below selective linear is copied to test harness one hot encode functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.linear_model as lm\n",
    "import sklearn.preprocessing as pre\n",
    "import sklearn.model_selection as ms\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "pd.options.display.max_columns=None\n",
    "\n",
    "import harness\n",
    "\n",
    "np.warnings.filterwarnings('ignore', 'Ill-conditioned matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_train = pd.read_csv('data/flights_train.csv', index_col=0)\n",
    "flights_test = pd.read_csv('data/flights_test.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_clean = harness.clean_train(flights_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_clean = harness.clean_train(flights_train)\n",
    "\n",
    "add_features = harness.chain(\n",
    "    harness.add_date_parts, harness.add_haul, harness.add_weather\n",
    ")\n",
    "\n",
    "flights_with_features = add_features(flights_clean)\n",
    "\n",
    "x_transform = harness.chain(\n",
    "    harness.keep_only_test_columns,\n",
    "    add_features,\n",
    "    [harness.add_all_grouped_stats, flights_with_features],\n",
    "    harness.only_numeric,\n",
    "    harness.scale,\n",
    ")\n",
    "\n",
    "transformer = harness.DataTransformer(\n",
    "    x_transform\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in x_train.columns:\n",
    "    print(f\"{col}: {np.corrcoef(x_train[col], y_train.arr_delay)[0, 1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_columns(df):\n",
    "    return df[[\n",
    "        'origin_airport_id_delay_mean',\n",
    "        'origin_airport_id_delay_std',\n",
    "        'dest_airport_id_delay_mean',\n",
    "        'dest_airport_id_delay_std',\n",
    "    ]]\n",
    "\n",
    "def train_model():\n",
    "    linreg = lm.Ridge(random_state=42)\n",
    "    grid_search = ms.GridSearchCV(\n",
    "        linreg, dict(alpha=[10 ** i for i in range(-6, 7)]),\n",
    "    )\n",
    "    grid_search.fit(x_train.values, y_train.values)\n",
    "    print(grid_search.best_score_)\n",
    "    harness.save(grid_search.best_estimator_, 'selective_linear_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_transform = harness.chain(x_transform, select_columns)\n",
    "transformer = harness.DataTransformer(\n",
    "    x_transform\n",
    ")\n",
    "x_train, y_train = transformer.extract_transform(flights_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg = harness.load('selective_linear_model')\n",
    "linreg_model = harness.TrainedModel(linreg, transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg_model.validate(harness.clean_train(flights_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linreg_model.submit(\n",
    "#     'data/test.csv', 'everything_linear_submission.csv', 'predicted_delay'\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_city_dummies(df):\n",
    "    cols = [\n",
    "        'origin_city_name', 'dest_city_name',\n",
    "        'origin_airport_id', 'dest_airport_id',\n",
    "    ]\n",
    "    for col in cols:\n",
    "        dummy = pd.get_dummies(df[col],prefix=col)\n",
    "        df = pd.concat([df,dummy], axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fl_date</th>\n",
       "      <th>mkt_unique_carrier</th>\n",
       "      <th>branded_code_share</th>\n",
       "      <th>mkt_carrier</th>\n",
       "      <th>mkt_carrier_fl_num</th>\n",
       "      <th>op_unique_carrier</th>\n",
       "      <th>tail_num</th>\n",
       "      <th>op_carrier_fl_num</th>\n",
       "      <th>origin_airport_id</th>\n",
       "      <th>origin</th>\n",
       "      <th>origin_city_name</th>\n",
       "      <th>dest_airport_id</th>\n",
       "      <th>dest</th>\n",
       "      <th>dest_city_name</th>\n",
       "      <th>crs_dep_time</th>\n",
       "      <th>dep_time</th>\n",
       "      <th>dep_delay</th>\n",
       "      <th>taxi_out</th>\n",
       "      <th>wheels_off</th>\n",
       "      <th>wheels_on</th>\n",
       "      <th>taxi_in</th>\n",
       "      <th>crs_arr_time</th>\n",
       "      <th>arr_time</th>\n",
       "      <th>arr_delay</th>\n",
       "      <th>cancelled</th>\n",
       "      <th>diverted</th>\n",
       "      <th>dup</th>\n",
       "      <th>crs_elapsed_time</th>\n",
       "      <th>actual_elapsed_time</th>\n",
       "      <th>air_time</th>\n",
       "      <th>flights</th>\n",
       "      <th>distance</th>\n",
       "      <th>origin_dest_city_name</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>121941</th>\n",
       "      <td>2019-08-25</td>\n",
       "      <td>AA</td>\n",
       "      <td>AA_CODESHARE</td>\n",
       "      <td>AA</td>\n",
       "      <td>5636</td>\n",
       "      <td>OH</td>\n",
       "      <td>N723PS</td>\n",
       "      <td>5636</td>\n",
       "      <td>11057</td>\n",
       "      <td>CLT</td>\n",
       "      <td>Charlotte, NC</td>\n",
       "      <td>10208</td>\n",
       "      <td>AGS</td>\n",
       "      <td>Augusta, GA</td>\n",
       "      <td>1818</td>\n",
       "      <td>1811.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1825.0</td>\n",
       "      <td>1856.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1921</td>\n",
       "      <td>1859.0</td>\n",
       "      <td>-22.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>63</td>\n",
       "      <td>48.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1</td>\n",
       "      <td>140</td>\n",
       "      <td>Charlotte, NC to Augusta, GA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109932</th>\n",
       "      <td>2018-03-02</td>\n",
       "      <td>WN</td>\n",
       "      <td>WN</td>\n",
       "      <td>WN</td>\n",
       "      <td>2028</td>\n",
       "      <td>WN</td>\n",
       "      <td>N244WN</td>\n",
       "      <td>2028</td>\n",
       "      <td>13495</td>\n",
       "      <td>MSY</td>\n",
       "      <td>New Orleans, LA</td>\n",
       "      <td>10693</td>\n",
       "      <td>BNA</td>\n",
       "      <td>Nashville, TN</td>\n",
       "      <td>745</td>\n",
       "      <td>738.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>745.0</td>\n",
       "      <td>851.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>915</td>\n",
       "      <td>855.0</td>\n",
       "      <td>-20.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>90</td>\n",
       "      <td>77.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>1</td>\n",
       "      <td>471</td>\n",
       "      <td>New Orleans, LA to Nashville, TN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63108</th>\n",
       "      <td>2019-03-06</td>\n",
       "      <td>UA</td>\n",
       "      <td>UA</td>\n",
       "      <td>UA</td>\n",
       "      <td>545</td>\n",
       "      <td>UA</td>\n",
       "      <td>N69804</td>\n",
       "      <td>545</td>\n",
       "      <td>11292</td>\n",
       "      <td>DEN</td>\n",
       "      <td>Denver, CO</td>\n",
       "      <td>12266</td>\n",
       "      <td>IAH</td>\n",
       "      <td>Houston, TX</td>\n",
       "      <td>1214</td>\n",
       "      <td>1233.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1245.0</td>\n",
       "      <td>1531.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1531</td>\n",
       "      <td>1535.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>137</td>\n",
       "      <td>122.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>1</td>\n",
       "      <td>862</td>\n",
       "      <td>Denver, CO to Houston, TX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91519</th>\n",
       "      <td>2019-10-11</td>\n",
       "      <td>DL</td>\n",
       "      <td>DL_CODESHARE</td>\n",
       "      <td>DL</td>\n",
       "      <td>3798</td>\n",
       "      <td>OO</td>\n",
       "      <td>N452SW</td>\n",
       "      <td>3798</td>\n",
       "      <td>16869</td>\n",
       "      <td>XWA</td>\n",
       "      <td>Williston, ND</td>\n",
       "      <td>13487</td>\n",
       "      <td>MSP</td>\n",
       "      <td>Minneapolis, MN</td>\n",
       "      <td>600</td>\n",
       "      <td>609.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>817.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>806</td>\n",
       "      <td>820.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>126</td>\n",
       "      <td>131.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>1</td>\n",
       "      <td>553</td>\n",
       "      <td>Williston, ND to Minneapolis, MN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8361</th>\n",
       "      <td>2019-09-26</td>\n",
       "      <td>UA</td>\n",
       "      <td>UA_CODESHARE</td>\n",
       "      <td>UA</td>\n",
       "      <td>5359</td>\n",
       "      <td>OO</td>\n",
       "      <td>N120SY</td>\n",
       "      <td>5359</td>\n",
       "      <td>10713</td>\n",
       "      <td>BOI</td>\n",
       "      <td>Boise, ID</td>\n",
       "      <td>14771</td>\n",
       "      <td>SFO</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>1426</td>\n",
       "      <td>1431.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1441.0</td>\n",
       "      <td>1504.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1521</td>\n",
       "      <td>1511.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>115</td>\n",
       "      <td>100.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>1</td>\n",
       "      <td>522</td>\n",
       "      <td>Boise, ID to San Francisco, CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48069</th>\n",
       "      <td>2019-05-01</td>\n",
       "      <td>G4</td>\n",
       "      <td>G4</td>\n",
       "      <td>G4</td>\n",
       "      <td>2170</td>\n",
       "      <td>G4</td>\n",
       "      <td>260NV</td>\n",
       "      <td>2170</td>\n",
       "      <td>14761</td>\n",
       "      <td>SFB</td>\n",
       "      <td>Sanford, FL</td>\n",
       "      <td>11973</td>\n",
       "      <td>GPT</td>\n",
       "      <td>Gulfport/Biloxi, MS</td>\n",
       "      <td>605</td>\n",
       "      <td>559.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>612.0</td>\n",
       "      <td>627.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>638</td>\n",
       "      <td>632.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>93</td>\n",
       "      <td>93.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>1</td>\n",
       "      <td>485</td>\n",
       "      <td>Sanford, FL to Gulfport/Biloxi, MS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68804</th>\n",
       "      <td>2019-07-01</td>\n",
       "      <td>UA</td>\n",
       "      <td>UA_CODESHARE</td>\n",
       "      <td>UA</td>\n",
       "      <td>6259</td>\n",
       "      <td>YV</td>\n",
       "      <td>N80343</td>\n",
       "      <td>6259</td>\n",
       "      <td>10140</td>\n",
       "      <td>ABQ</td>\n",
       "      <td>Albuquerque, NM</td>\n",
       "      <td>12266</td>\n",
       "      <td>IAH</td>\n",
       "      <td>Houston, TX</td>\n",
       "      <td>540</td>\n",
       "      <td>553.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>605.0</td>\n",
       "      <td>853.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>851</td>\n",
       "      <td>856.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>131</td>\n",
       "      <td>123.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>1</td>\n",
       "      <td>744</td>\n",
       "      <td>Albuquerque, NM to Houston, TX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43542</th>\n",
       "      <td>2018-07-12</td>\n",
       "      <td>AA</td>\n",
       "      <td>AA</td>\n",
       "      <td>AA</td>\n",
       "      <td>412</td>\n",
       "      <td>AA</td>\n",
       "      <td>N177US</td>\n",
       "      <td>412</td>\n",
       "      <td>11057</td>\n",
       "      <td>CLT</td>\n",
       "      <td>Charlotte, NC</td>\n",
       "      <td>14107</td>\n",
       "      <td>PHX</td>\n",
       "      <td>Phoenix, AZ</td>\n",
       "      <td>1300</td>\n",
       "      <td>1313.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>1408.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1415</td>\n",
       "      <td>1413.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>255</td>\n",
       "      <td>240.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1773</td>\n",
       "      <td>Charlotte, NC to Phoenix, AZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100583</th>\n",
       "      <td>2018-11-21</td>\n",
       "      <td>AA</td>\n",
       "      <td>AA</td>\n",
       "      <td>AA</td>\n",
       "      <td>1252</td>\n",
       "      <td>AA</td>\n",
       "      <td>N136AN</td>\n",
       "      <td>1252</td>\n",
       "      <td>11298</td>\n",
       "      <td>DFW</td>\n",
       "      <td>Dallas/Fort Worth, TX</td>\n",
       "      <td>14893</td>\n",
       "      <td>SMF</td>\n",
       "      <td>Sacramento, CA</td>\n",
       "      <td>1855</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>2137.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2056</td>\n",
       "      <td>2145.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>241</td>\n",
       "      <td>218.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1431</td>\n",
       "      <td>Dallas/Fort Worth, TX to Sacramento, CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23677</th>\n",
       "      <td>2018-02-08</td>\n",
       "      <td>DL</td>\n",
       "      <td>DL</td>\n",
       "      <td>DL</td>\n",
       "      <td>808</td>\n",
       "      <td>DL</td>\n",
       "      <td>N374NW</td>\n",
       "      <td>808</td>\n",
       "      <td>13487</td>\n",
       "      <td>MSP</td>\n",
       "      <td>Minneapolis, MN</td>\n",
       "      <td>10721</td>\n",
       "      <td>BOS</td>\n",
       "      <td>Boston, MA</td>\n",
       "      <td>655</td>\n",
       "      <td>650.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>716.0</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1055</td>\n",
       "      <td>1030.0</td>\n",
       "      <td>-25.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>180</td>\n",
       "      <td>160.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1124</td>\n",
       "      <td>Minneapolis, MN to Boston, MA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>125434 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           fl_date mkt_unique_carrier branded_code_share mkt_carrier  \\\n",
       "id                                                                     \n",
       "121941  2019-08-25                 AA       AA_CODESHARE          AA   \n",
       "109932  2018-03-02                 WN                 WN          WN   \n",
       "63108   2019-03-06                 UA                 UA          UA   \n",
       "91519   2019-10-11                 DL       DL_CODESHARE          DL   \n",
       "8361    2019-09-26                 UA       UA_CODESHARE          UA   \n",
       "...            ...                ...                ...         ...   \n",
       "48069   2019-05-01                 G4                 G4          G4   \n",
       "68804   2019-07-01                 UA       UA_CODESHARE          UA   \n",
       "43542   2018-07-12                 AA                 AA          AA   \n",
       "100583  2018-11-21                 AA                 AA          AA   \n",
       "23677   2018-02-08                 DL                 DL          DL   \n",
       "\n",
       "        mkt_carrier_fl_num op_unique_carrier tail_num  op_carrier_fl_num  \\\n",
       "id                                                                         \n",
       "121941                5636                OH   N723PS               5636   \n",
       "109932                2028                WN   N244WN               2028   \n",
       "63108                  545                UA   N69804                545   \n",
       "91519                 3798                OO   N452SW               3798   \n",
       "8361                  5359                OO   N120SY               5359   \n",
       "...                    ...               ...      ...                ...   \n",
       "48069                 2170                G4    260NV               2170   \n",
       "68804                 6259                YV   N80343               6259   \n",
       "43542                  412                AA   N177US                412   \n",
       "100583                1252                AA   N136AN               1252   \n",
       "23677                  808                DL   N374NW                808   \n",
       "\n",
       "        origin_airport_id origin       origin_city_name  dest_airport_id dest  \\\n",
       "id                                                                              \n",
       "121941              11057    CLT          Charlotte, NC            10208  AGS   \n",
       "109932              13495    MSY        New Orleans, LA            10693  BNA   \n",
       "63108               11292    DEN             Denver, CO            12266  IAH   \n",
       "91519               16869    XWA          Williston, ND            13487  MSP   \n",
       "8361                10713    BOI              Boise, ID            14771  SFO   \n",
       "...                   ...    ...                    ...              ...  ...   \n",
       "48069               14761    SFB            Sanford, FL            11973  GPT   \n",
       "68804               10140    ABQ        Albuquerque, NM            12266  IAH   \n",
       "43542               11057    CLT          Charlotte, NC            14107  PHX   \n",
       "100583              11298    DFW  Dallas/Fort Worth, TX            14893  SMF   \n",
       "23677               13487    MSP        Minneapolis, MN            10721  BOS   \n",
       "\n",
       "             dest_city_name  crs_dep_time  dep_time  dep_delay  taxi_out  \\\n",
       "id                                                                         \n",
       "121941          Augusta, GA          1818    1811.0       -7.0      14.0   \n",
       "109932        Nashville, TN           745     738.0       -7.0       7.0   \n",
       "63108           Houston, TX          1214    1233.0       19.0      12.0   \n",
       "91519       Minneapolis, MN           600     609.0        9.0      31.0   \n",
       "8361      San Francisco, CA          1426    1431.0        5.0      10.0   \n",
       "...                     ...           ...       ...        ...       ...   \n",
       "48069   Gulfport/Biloxi, MS           605     559.0       -6.0      13.0   \n",
       "68804           Houston, TX           540     553.0       13.0      12.0   \n",
       "43542           Phoenix, AZ          1300    1313.0       13.0      13.0   \n",
       "100583       Sacramento, CA          1855    2007.0       72.0      15.0   \n",
       "23677            Boston, MA           655     650.0       -5.0      26.0   \n",
       "\n",
       "        wheels_off  wheels_on  taxi_in  crs_arr_time  arr_time  arr_delay  \\\n",
       "id                                                                          \n",
       "121941      1825.0     1856.0      3.0          1921    1859.0      -22.0   \n",
       "109932       745.0      851.0      4.0           915     855.0      -20.0   \n",
       "63108       1245.0     1531.0      4.0          1531    1535.0        4.0   \n",
       "91519        640.0      817.0      3.0           806     820.0       14.0   \n",
       "8361        1441.0     1504.0      7.0          1521    1511.0      -10.0   \n",
       "...            ...        ...      ...           ...       ...        ...   \n",
       "48069        612.0      627.0      5.0           638     632.0       -6.0   \n",
       "68804        605.0      853.0      3.0           851     856.0        5.0   \n",
       "43542       1326.0     1408.0      5.0          1415    1413.0       -2.0   \n",
       "100583      2022.0     2137.0      8.0          2056    2145.0       49.0   \n",
       "23677        716.0     1024.0      6.0          1055    1030.0      -25.0   \n",
       "\n",
       "        cancelled  diverted dup  crs_elapsed_time  actual_elapsed_time  \\\n",
       "id                                                                       \n",
       "121941          0         0   N                63                 48.0   \n",
       "109932          0         0   N                90                 77.0   \n",
       "63108           0         0   N               137                122.0   \n",
       "91519           0         0   N               126                131.0   \n",
       "8361            0         0   N               115                100.0   \n",
       "...           ...       ...  ..               ...                  ...   \n",
       "48069           0         0   N                93                 93.0   \n",
       "68804           0         0   N               131                123.0   \n",
       "43542           0         0   N               255                240.0   \n",
       "100583          0         0   N               241                218.0   \n",
       "23677           0         0   N               180                160.0   \n",
       "\n",
       "        air_time  flights  distance                    origin_dest_city_name  \n",
       "id                                                                            \n",
       "121941      31.0        1       140             Charlotte, NC to Augusta, GA  \n",
       "109932      66.0        1       471         New Orleans, LA to Nashville, TN  \n",
       "63108      106.0        1       862                Denver, CO to Houston, TX  \n",
       "91519       97.0        1       553         Williston, ND to Minneapolis, MN  \n",
       "8361        83.0        1       522           Boise, ID to San Francisco, CA  \n",
       "...          ...      ...       ...                                      ...  \n",
       "48069       75.0        1       485       Sanford, FL to Gulfport/Biloxi, MS  \n",
       "68804      108.0        1       744           Albuquerque, NM to Houston, TX  \n",
       "43542      222.0        1      1773             Charlotte, NC to Phoenix, AZ  \n",
       "100583     195.0        1      1431  Dallas/Fort Worth, TX to Sacramento, CA  \n",
       "23677      128.0        1      1124            Minneapolis, MN to Boston, MA  \n",
       "\n",
       "[125434 rows x 33 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flights_copy = flights_clean.copy()\n",
    "\n",
    "flights_copy['origin_dest_city_name'] = flights_copy['origin_city_name']+' to '+flights_copy['dest_city_name']\n",
    "\n",
    "flights_copy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fl_date</th>\n",
       "      <th>mkt_unique_carrier</th>\n",
       "      <th>branded_code_share</th>\n",
       "      <th>mkt_carrier</th>\n",
       "      <th>mkt_carrier_fl_num</th>\n",
       "      <th>op_unique_carrier</th>\n",
       "      <th>tail_num</th>\n",
       "      <th>op_carrier_fl_num</th>\n",
       "      <th>origin_airport_id</th>\n",
       "      <th>origin</th>\n",
       "      <th>origin_city_name</th>\n",
       "      <th>dest_airport_id</th>\n",
       "      <th>dest</th>\n",
       "      <th>dest_city_name</th>\n",
       "      <th>crs_dep_time</th>\n",
       "      <th>dep_time</th>\n",
       "      <th>dep_delay</th>\n",
       "      <th>taxi_out</th>\n",
       "      <th>wheels_off</th>\n",
       "      <th>wheels_on</th>\n",
       "      <th>taxi_in</th>\n",
       "      <th>crs_arr_time</th>\n",
       "      <th>arr_time</th>\n",
       "      <th>arr_delay</th>\n",
       "      <th>cancelled</th>\n",
       "      <th>diverted</th>\n",
       "      <th>dup</th>\n",
       "      <th>crs_elapsed_time</th>\n",
       "      <th>actual_elapsed_time</th>\n",
       "      <th>air_time</th>\n",
       "      <th>flights</th>\n",
       "      <th>distance</th>\n",
       "      <th>origin_dest_airport_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>121941</th>\n",
       "      <td>2019-08-25</td>\n",
       "      <td>AA</td>\n",
       "      <td>AA_CODESHARE</td>\n",
       "      <td>AA</td>\n",
       "      <td>5636</td>\n",
       "      <td>OH</td>\n",
       "      <td>N723PS</td>\n",
       "      <td>5636</td>\n",
       "      <td>11057</td>\n",
       "      <td>CLT</td>\n",
       "      <td>Charlotte, NC</td>\n",
       "      <td>10208</td>\n",
       "      <td>AGS</td>\n",
       "      <td>Augusta, GA</td>\n",
       "      <td>1818</td>\n",
       "      <td>1811.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1825.0</td>\n",
       "      <td>1856.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1921</td>\n",
       "      <td>1859.0</td>\n",
       "      <td>-22.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>63</td>\n",
       "      <td>48.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1</td>\n",
       "      <td>140</td>\n",
       "      <td>11057 to 10208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109932</th>\n",
       "      <td>2018-03-02</td>\n",
       "      <td>WN</td>\n",
       "      <td>WN</td>\n",
       "      <td>WN</td>\n",
       "      <td>2028</td>\n",
       "      <td>WN</td>\n",
       "      <td>N244WN</td>\n",
       "      <td>2028</td>\n",
       "      <td>13495</td>\n",
       "      <td>MSY</td>\n",
       "      <td>New Orleans, LA</td>\n",
       "      <td>10693</td>\n",
       "      <td>BNA</td>\n",
       "      <td>Nashville, TN</td>\n",
       "      <td>745</td>\n",
       "      <td>738.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>745.0</td>\n",
       "      <td>851.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>915</td>\n",
       "      <td>855.0</td>\n",
       "      <td>-20.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>90</td>\n",
       "      <td>77.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>1</td>\n",
       "      <td>471</td>\n",
       "      <td>13495 to 10693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63108</th>\n",
       "      <td>2019-03-06</td>\n",
       "      <td>UA</td>\n",
       "      <td>UA</td>\n",
       "      <td>UA</td>\n",
       "      <td>545</td>\n",
       "      <td>UA</td>\n",
       "      <td>N69804</td>\n",
       "      <td>545</td>\n",
       "      <td>11292</td>\n",
       "      <td>DEN</td>\n",
       "      <td>Denver, CO</td>\n",
       "      <td>12266</td>\n",
       "      <td>IAH</td>\n",
       "      <td>Houston, TX</td>\n",
       "      <td>1214</td>\n",
       "      <td>1233.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1245.0</td>\n",
       "      <td>1531.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1531</td>\n",
       "      <td>1535.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>137</td>\n",
       "      <td>122.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>1</td>\n",
       "      <td>862</td>\n",
       "      <td>11292 to 12266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91519</th>\n",
       "      <td>2019-10-11</td>\n",
       "      <td>DL</td>\n",
       "      <td>DL_CODESHARE</td>\n",
       "      <td>DL</td>\n",
       "      <td>3798</td>\n",
       "      <td>OO</td>\n",
       "      <td>N452SW</td>\n",
       "      <td>3798</td>\n",
       "      <td>16869</td>\n",
       "      <td>XWA</td>\n",
       "      <td>Williston, ND</td>\n",
       "      <td>13487</td>\n",
       "      <td>MSP</td>\n",
       "      <td>Minneapolis, MN</td>\n",
       "      <td>600</td>\n",
       "      <td>609.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>817.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>806</td>\n",
       "      <td>820.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>126</td>\n",
       "      <td>131.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>1</td>\n",
       "      <td>553</td>\n",
       "      <td>16869 to 13487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8361</th>\n",
       "      <td>2019-09-26</td>\n",
       "      <td>UA</td>\n",
       "      <td>UA_CODESHARE</td>\n",
       "      <td>UA</td>\n",
       "      <td>5359</td>\n",
       "      <td>OO</td>\n",
       "      <td>N120SY</td>\n",
       "      <td>5359</td>\n",
       "      <td>10713</td>\n",
       "      <td>BOI</td>\n",
       "      <td>Boise, ID</td>\n",
       "      <td>14771</td>\n",
       "      <td>SFO</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>1426</td>\n",
       "      <td>1431.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1441.0</td>\n",
       "      <td>1504.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1521</td>\n",
       "      <td>1511.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>115</td>\n",
       "      <td>100.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>1</td>\n",
       "      <td>522</td>\n",
       "      <td>10713 to 14771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48069</th>\n",
       "      <td>2019-05-01</td>\n",
       "      <td>G4</td>\n",
       "      <td>G4</td>\n",
       "      <td>G4</td>\n",
       "      <td>2170</td>\n",
       "      <td>G4</td>\n",
       "      <td>260NV</td>\n",
       "      <td>2170</td>\n",
       "      <td>14761</td>\n",
       "      <td>SFB</td>\n",
       "      <td>Sanford, FL</td>\n",
       "      <td>11973</td>\n",
       "      <td>GPT</td>\n",
       "      <td>Gulfport/Biloxi, MS</td>\n",
       "      <td>605</td>\n",
       "      <td>559.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>612.0</td>\n",
       "      <td>627.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>638</td>\n",
       "      <td>632.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>93</td>\n",
       "      <td>93.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>1</td>\n",
       "      <td>485</td>\n",
       "      <td>14761 to 11973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68804</th>\n",
       "      <td>2019-07-01</td>\n",
       "      <td>UA</td>\n",
       "      <td>UA_CODESHARE</td>\n",
       "      <td>UA</td>\n",
       "      <td>6259</td>\n",
       "      <td>YV</td>\n",
       "      <td>N80343</td>\n",
       "      <td>6259</td>\n",
       "      <td>10140</td>\n",
       "      <td>ABQ</td>\n",
       "      <td>Albuquerque, NM</td>\n",
       "      <td>12266</td>\n",
       "      <td>IAH</td>\n",
       "      <td>Houston, TX</td>\n",
       "      <td>540</td>\n",
       "      <td>553.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>605.0</td>\n",
       "      <td>853.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>851</td>\n",
       "      <td>856.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>131</td>\n",
       "      <td>123.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>1</td>\n",
       "      <td>744</td>\n",
       "      <td>10140 to 12266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43542</th>\n",
       "      <td>2018-07-12</td>\n",
       "      <td>AA</td>\n",
       "      <td>AA</td>\n",
       "      <td>AA</td>\n",
       "      <td>412</td>\n",
       "      <td>AA</td>\n",
       "      <td>N177US</td>\n",
       "      <td>412</td>\n",
       "      <td>11057</td>\n",
       "      <td>CLT</td>\n",
       "      <td>Charlotte, NC</td>\n",
       "      <td>14107</td>\n",
       "      <td>PHX</td>\n",
       "      <td>Phoenix, AZ</td>\n",
       "      <td>1300</td>\n",
       "      <td>1313.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>1408.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1415</td>\n",
       "      <td>1413.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>255</td>\n",
       "      <td>240.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1773</td>\n",
       "      <td>11057 to 14107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100583</th>\n",
       "      <td>2018-11-21</td>\n",
       "      <td>AA</td>\n",
       "      <td>AA</td>\n",
       "      <td>AA</td>\n",
       "      <td>1252</td>\n",
       "      <td>AA</td>\n",
       "      <td>N136AN</td>\n",
       "      <td>1252</td>\n",
       "      <td>11298</td>\n",
       "      <td>DFW</td>\n",
       "      <td>Dallas/Fort Worth, TX</td>\n",
       "      <td>14893</td>\n",
       "      <td>SMF</td>\n",
       "      <td>Sacramento, CA</td>\n",
       "      <td>1855</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>2137.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2056</td>\n",
       "      <td>2145.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>241</td>\n",
       "      <td>218.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1431</td>\n",
       "      <td>11298 to 14893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23677</th>\n",
       "      <td>2018-02-08</td>\n",
       "      <td>DL</td>\n",
       "      <td>DL</td>\n",
       "      <td>DL</td>\n",
       "      <td>808</td>\n",
       "      <td>DL</td>\n",
       "      <td>N374NW</td>\n",
       "      <td>808</td>\n",
       "      <td>13487</td>\n",
       "      <td>MSP</td>\n",
       "      <td>Minneapolis, MN</td>\n",
       "      <td>10721</td>\n",
       "      <td>BOS</td>\n",
       "      <td>Boston, MA</td>\n",
       "      <td>655</td>\n",
       "      <td>650.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>716.0</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1055</td>\n",
       "      <td>1030.0</td>\n",
       "      <td>-25.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>180</td>\n",
       "      <td>160.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1124</td>\n",
       "      <td>13487 to 10721</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>125434 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           fl_date mkt_unique_carrier branded_code_share mkt_carrier  \\\n",
       "id                                                                     \n",
       "121941  2019-08-25                 AA       AA_CODESHARE          AA   \n",
       "109932  2018-03-02                 WN                 WN          WN   \n",
       "63108   2019-03-06                 UA                 UA          UA   \n",
       "91519   2019-10-11                 DL       DL_CODESHARE          DL   \n",
       "8361    2019-09-26                 UA       UA_CODESHARE          UA   \n",
       "...            ...                ...                ...         ...   \n",
       "48069   2019-05-01                 G4                 G4          G4   \n",
       "68804   2019-07-01                 UA       UA_CODESHARE          UA   \n",
       "43542   2018-07-12                 AA                 AA          AA   \n",
       "100583  2018-11-21                 AA                 AA          AA   \n",
       "23677   2018-02-08                 DL                 DL          DL   \n",
       "\n",
       "        mkt_carrier_fl_num op_unique_carrier tail_num  op_carrier_fl_num  \\\n",
       "id                                                                         \n",
       "121941                5636                OH   N723PS               5636   \n",
       "109932                2028                WN   N244WN               2028   \n",
       "63108                  545                UA   N69804                545   \n",
       "91519                 3798                OO   N452SW               3798   \n",
       "8361                  5359                OO   N120SY               5359   \n",
       "...                    ...               ...      ...                ...   \n",
       "48069                 2170                G4    260NV               2170   \n",
       "68804                 6259                YV   N80343               6259   \n",
       "43542                  412                AA   N177US                412   \n",
       "100583                1252                AA   N136AN               1252   \n",
       "23677                  808                DL   N374NW                808   \n",
       "\n",
       "        origin_airport_id origin       origin_city_name  dest_airport_id dest  \\\n",
       "id                                                                              \n",
       "121941              11057    CLT          Charlotte, NC            10208  AGS   \n",
       "109932              13495    MSY        New Orleans, LA            10693  BNA   \n",
       "63108               11292    DEN             Denver, CO            12266  IAH   \n",
       "91519               16869    XWA          Williston, ND            13487  MSP   \n",
       "8361                10713    BOI              Boise, ID            14771  SFO   \n",
       "...                   ...    ...                    ...              ...  ...   \n",
       "48069               14761    SFB            Sanford, FL            11973  GPT   \n",
       "68804               10140    ABQ        Albuquerque, NM            12266  IAH   \n",
       "43542               11057    CLT          Charlotte, NC            14107  PHX   \n",
       "100583              11298    DFW  Dallas/Fort Worth, TX            14893  SMF   \n",
       "23677               13487    MSP        Minneapolis, MN            10721  BOS   \n",
       "\n",
       "             dest_city_name  crs_dep_time  dep_time  dep_delay  taxi_out  \\\n",
       "id                                                                         \n",
       "121941          Augusta, GA          1818    1811.0       -7.0      14.0   \n",
       "109932        Nashville, TN           745     738.0       -7.0       7.0   \n",
       "63108           Houston, TX          1214    1233.0       19.0      12.0   \n",
       "91519       Minneapolis, MN           600     609.0        9.0      31.0   \n",
       "8361      San Francisco, CA          1426    1431.0        5.0      10.0   \n",
       "...                     ...           ...       ...        ...       ...   \n",
       "48069   Gulfport/Biloxi, MS           605     559.0       -6.0      13.0   \n",
       "68804           Houston, TX           540     553.0       13.0      12.0   \n",
       "43542           Phoenix, AZ          1300    1313.0       13.0      13.0   \n",
       "100583       Sacramento, CA          1855    2007.0       72.0      15.0   \n",
       "23677            Boston, MA           655     650.0       -5.0      26.0   \n",
       "\n",
       "        wheels_off  wheels_on  taxi_in  crs_arr_time  arr_time  arr_delay  \\\n",
       "id                                                                          \n",
       "121941      1825.0     1856.0      3.0          1921    1859.0      -22.0   \n",
       "109932       745.0      851.0      4.0           915     855.0      -20.0   \n",
       "63108       1245.0     1531.0      4.0          1531    1535.0        4.0   \n",
       "91519        640.0      817.0      3.0           806     820.0       14.0   \n",
       "8361        1441.0     1504.0      7.0          1521    1511.0      -10.0   \n",
       "...            ...        ...      ...           ...       ...        ...   \n",
       "48069        612.0      627.0      5.0           638     632.0       -6.0   \n",
       "68804        605.0      853.0      3.0           851     856.0        5.0   \n",
       "43542       1326.0     1408.0      5.0          1415    1413.0       -2.0   \n",
       "100583      2022.0     2137.0      8.0          2056    2145.0       49.0   \n",
       "23677        716.0     1024.0      6.0          1055    1030.0      -25.0   \n",
       "\n",
       "        cancelled  diverted dup  crs_elapsed_time  actual_elapsed_time  \\\n",
       "id                                                                       \n",
       "121941          0         0   N                63                 48.0   \n",
       "109932          0         0   N                90                 77.0   \n",
       "63108           0         0   N               137                122.0   \n",
       "91519           0         0   N               126                131.0   \n",
       "8361            0         0   N               115                100.0   \n",
       "...           ...       ...  ..               ...                  ...   \n",
       "48069           0         0   N                93                 93.0   \n",
       "68804           0         0   N               131                123.0   \n",
       "43542           0         0   N               255                240.0   \n",
       "100583          0         0   N               241                218.0   \n",
       "23677           0         0   N               180                160.0   \n",
       "\n",
       "        air_time  flights  distance origin_dest_airport_id  \n",
       "id                                                          \n",
       "121941      31.0        1       140         11057 to 10208  \n",
       "109932      66.0        1       471         13495 to 10693  \n",
       "63108      106.0        1       862         11292 to 12266  \n",
       "91519       97.0        1       553         16869 to 13487  \n",
       "8361        83.0        1       522         10713 to 14771  \n",
       "...          ...      ...       ...                    ...  \n",
       "48069       75.0        1       485         14761 to 11973  \n",
       "68804      108.0        1       744         10140 to 12266  \n",
       "43542      222.0        1      1773         11057 to 14107  \n",
       "100583     195.0        1      1431         11298 to 14893  \n",
       "23677      128.0        1      1124         13487 to 10721  \n",
       "\n",
       "[125434 rows x 33 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df['origin_dest_airport_id'] = df['origin_airport_id']+' to '+df['dest_airport_id']\n",
    "\n",
    "    \n",
    "flights_copy = flights_clean.copy()\n",
    "\n",
    "flights_copy['origin_dest_airport_id'] = flights_copy['origin_airport_id'].map(lambda v: str(v))+' to '+flights_copy['dest_airport_id'].map(lambda v: str(v))\n",
    "    \n",
    "df['origin_dest_airport_id']  =df['origin_airport_id'].map(lambda v: str(v))+' to '+df['dest_airport_id'].map(lambda v: str(v))\n",
    "    \n",
    "df['origin_dest_airport_id'] = df['origin_airport_id']+' to '+df['dest_airport_id']\n",
    "\n",
    "flights_copy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have data from 2018 and 2019 to develop models. Use different evaluation metrics for each problem and compare the performance of different models.\n",
    "\n",
    "You are required to predict delays on **out of sample** data from **first 7 days (1st-7th) of January 2020** and to share the file with LighthouseLabs. Sample submission can be found in the file **_sample_submission.csv_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "======================================================================\n",
    "## Stretch Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiclass Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The target variables are **CARRIER_DELAY, WEATHER_DELAY, NAS_DELAY, SECURITY_DELAY, LATE_AIRCRAFT_DELAY**. We need to do additional transformations because these variables are not binary but continuos. For each flight that was delayed, we need to have one of these variables as 1 and others 0.\n",
    "\n",
    "It can happen that we have two types of delays with more than 0 minutes. In this case, take the bigger one as 1 and others as 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The target variable is **CANCELLED**. The main problem here is going to be huge class imbalance. We have only very little cancelled flights with comparison to all flights. It is important to do the right sampling before training and to choose correct evaluation metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
